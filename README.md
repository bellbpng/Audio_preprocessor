## STT 성능 향상을 위한 딥러닝 기반 음성 신호 필터 개발

예능 콘텐츠에 대한 STT(Speech-To-Text) 엔진 성능 향상을 위한 딥러닝 기반 음성 신호 필터 개발 프로젝트

### STT 엔진 구조

<img src="https://github.com/tsurumeso/vocal-remover/assets/59792046/d953e301-358c-4864-bfca-11131c48594d">

- STT 엔진은 위 그립과 같이 입력되는 음성에 대해 분석, 잡음처리 등을 거쳐 학습부(음향모델, 언어모델)에서 필요한 특징 정보를 추출하는 **전처리** 엔진과 전달 받은 데이터로 추론을 담당하는 **학습부(음향모델, 언어모델)** 구조로 이루어져 있다.
- 해당 프로젝트는 STT 엔진 중 전처리 단계에서 수행하는 음성 특징 정보 추출, 잡음 처리 등의 성능을 향상시켜 학습부의 추론으로 텍스트 변환의 정확도를 향상시키기 위한 목적을 지니며, 최종적으로 예능 콘텐츠와 같은 비음성 신호와 음성 신호가 혼잡된 데이터에 대한 STT 성능을 향상시키기 위해 진행한 프로젝트이다.

### Vocal Remover
- 해당 연구를 위해 사용한 pre-trained network 이다.
- 자세한 내용은 [vocal-remover](https://github.com/tsurumeso/vocal-remover) 에서 살펴볼 수 있다.
- AR(All Recorded) 음원 파일에서 MR(Music Recorded) 파일을 추출하는 딥러닝 네트워크 모델로 본 연구에서는 데이터셋 구축 과정과 구축된 데이터셋에 대한 fine-tuning 작업을 위해 사용되었다.

<img src="https://github.com/tsurumeso/vocal-remover/assets/59792046/45e04976-38b1-4397-92ed-37cf482413a5">


### 데이터셋 구축
- 예능 콘텐츠의 경우 텍스트의 형태로 존재하는 명확한 정답 데이터가 없다. 따라서, 아래와 같이 데이터셋을 구축하는 작업을 진행하였다.

<img src="https://github.com/tsurumeso/vocal-remover/assets/59792046/d0321883-b730-4b6a-b3c2-b46c0c4e5611">

- 원본오디오에서 Vocal Remover 를 통해 비음성 신호를 필터링하고, 특정 임계값을 기준으로 비음성 신호가 강한 구간과 약한 구간을 찾는다.
- 예능 콘텐츠와 같은 오디오 데이터는 잡음이 적고 음성 신호가 안정적으로 존재하는 구간을 수작업으로 명확히 파악하는 작업에 한계가 있다. 따라서, 비음성 신호를 1차적으로 필터링하여 비음성 신호가 약하게 존재하는 구간을 찾는다. 해당 구간에는 음성 신호가 잡음에 의한 방해 없이 안정적으로 존재할 확률이 높다.
- 음성신호가 안정적으로 존재할 수 있는 구간을 원본오디오에서 파싱하여 concat 과정을 통해 하나의 오디오 데이터로 만든다. -> **훈련 데이터**
- **훈련 데이터** 에 다양한 구간의 비음성 신호가 랜덤하게 혼합된 비음성 신호를 덮어 하나의 오데오 데이터로 만든다. -> **정답 데이터**

<img src="https://github.com/tsurumeso/vocal-remover/assets/59792046/464fb8ef-5c7f-46e2-bc0e-2775f1d94287">

### Train and Inference
- 모델 훈련 후 결과의 추출은 상용 STT API를 활용한다.
- 본 연구에서는 Google Cloud Speech-to-Text API 를 활용하였다.